"""
Model Toolkit - ç”¨äºåˆ†æå’Œä¿®æ”¹Stable Diffusionæ¨¡å‹çš„å·¥å…·åŒ…
"""

import os
import torch
import safetensors.torch
from collections import defaultdict
import folder_paths
import logging
import sys

# ç®€åŒ–æ—¥å¿—é…ç½®
logging.basicConfig(
    stream=sys.stdout,
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# è®¾ç½®ç»„ä»¶è·¯å¾„
components_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "components")
folder_paths.add_model_folder_path("components", components_path)

# è·å–å½“å‰ç›®å½•è·¯å¾„
dir_path = os.path.dirname(__file__)

class ModelUtils:
    """æ¨¡å‹å·¥å…·ç±» - æä¾›æ¨¡å‹å¤„ç†çš„æ ¸å¿ƒåŠŸèƒ½"""
    
    COMPONENT_TYPES = {
        'UNET': 'diffusion_model',
        'VAE': ['first_stage_model', 'encoder', 'decoder', 'quant_conv'],
        'CLIP': ['cond_stage_model', 'text_model', 'transformer'],
        'EMA': 'model_ema'
    }
    
    ARCH_FEATURES = {
        'SDXL': 'text_model_2',
        'SD2.x': 'v_pred'
    }
    
    @staticmethod
    def format_size(size_in_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        units = ['B', 'KB', 'MB', 'GB', 'TB']
        size = float(size_in_bytes)
        unit_index = 0
        
        while size >= 1024.0 and unit_index < len(units) - 1:
            size /= 1024.0
            unit_index += 1
            
        return f"{size:.2f} {units[unit_index]}"

    @staticmethod
    def format_params(num):
        """æ ¼å¼åŒ–å‚æ•°æ•°é‡"""
        if num >= 1e9:
            return f"{num/1e9:.2f}B"
        else:
            return f"{num/1e6:.2f}M"

    @staticmethod
    def load_model(model_path):
        """åŠ è½½æ¨¡å‹æ–‡ä»¶"""
        try:
            if model_path.endswith('.safetensors'):
                model_data = safetensors.torch.load_file(model_path, device="cpu")
            else:
                model_data = torch.load(model_path, map_location="cpu")
                if "state_dict" in model_data:
                    model_data = model_data["state_dict"]
            return model_data
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            return None

    @classmethod
    def group_model_keys(cls, model_data):
        """å°†æ¨¡å‹é”®å€¼æŒ‰ç»„ä»¶åˆ†ç»„"""
        groups = defaultdict(list)
        
        for key in model_data.keys():
            grouped = False
            for comp_name, patterns in cls.COMPONENT_TYPES.items():
                if isinstance(patterns, list):
                    if any(p in key for p in patterns):
                        groups[comp_name].append(key)
                        grouped = True
                        break
                elif patterns in key:
                    groups[comp_name].append(key)
                    grouped = True
                    break
            
            if not grouped:
                groups['å…¶ä»–'].append(key)
        
        return groups

    @classmethod
    def analyze_architecture(cls, model_data):
        """åˆ†ææ¨¡å‹æ¶æ„"""
        if not model_data:
            return "æœªçŸ¥"
        
        for arch_type, feature in cls.ARCH_FEATURES.items():
            if any(feature in k for k in model_data.keys()):
                return arch_type
                
        return "SD1.x"

    @staticmethod
    def save_component(component_data, output_path):
        """ä¿å­˜æ¨¡å‹ç»„ä»¶"""
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            if output_path.endswith('.safetensors'):
                safetensors.torch.save_file(component_data, output_path)
            else:
                torch.save({"state_dict": component_data}, output_path)
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜ç»„ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False

    @staticmethod
    def validate_compatibility(source_comp, target_comp):
        """éªŒè¯ç»„ä»¶å…¼å®¹æ€§"""
        try:
            for key in source_comp:
                if key not in target_comp:
                    return False
                if source_comp[key].shape != target_comp[key].shape:
                    return False
            return True
        except Exception as e:
            logger.error(f"éªŒè¯å…¼å®¹æ€§æ—¶å‡ºé”™: {str(e)}")
            return False

# å¯¼å…¥èŠ‚ç‚¹ç±»
from .nodes.checkpoint_inspector import CheckpointInspector
from .nodes.component_extractor import ComponentExtractor
from .nodes.component_replacer import ComponentReplacer
from .nodes.unet_inspector import UNetInspector

# èŠ‚ç‚¹ç±»æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelInspector": CheckpointInspector,
    "ComponentExtractor": ComponentExtractor,
    "ComponentReplacer": ComponentReplacer,
    "UNetInspector": UNetInspector
}

# æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelInspector": "ğŸ” æ¨¡å‹æ£€æŸ¥å™¨",
    "ComponentExtractor": "ğŸ“¤ ç»„ä»¶æå–å™¨",
    "ComponentReplacer": "ğŸ”„ ç»„ä»¶æ›¿æ¢å™¨", 
    "UNetInspector": "ğŸ”¬ UNETæ£€æŸ¥å™¨"
}

# ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
if not hasattr(folder_paths, 'add_model_folder_path'):
    logger.warning("æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬ComfyUIï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

if not hasattr(folder_paths, 'get_filename_list'):
    logger.error("ä¸å…¼å®¹çš„ComfyUIç‰ˆæœ¬ï¼Œè¯·å‡çº§åˆ°v1.0+")

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "1.0.0" 